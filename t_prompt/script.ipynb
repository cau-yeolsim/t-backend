{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8caf8fcdde636cf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e5fac32d0e473",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "필요한 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d604da2ddd7d0e10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T08:09:36.862025Z",
     "start_time": "2023-11-30T08:09:36.486507Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: = not found\n",
      "zsh:1: = not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: = not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai == 0.28.1\n",
    "!pip install jupyter == 1.0.0\n",
    "!pip install langchain == 0.0.304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "099fbea4-82c3-46d0-8d75-20b30d36fab0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: = not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (4.35.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (0.16.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (0.19.4)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.11.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone-client == 2.2.4\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9815cf4e337745",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T08:09:38.925534Z",
     "start_time": "2023-11-30T08:09:38.923344Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    ")\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1087633-4285-44ab-9d51-edb97d26a15a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Pinecone 초기화\n",
    "pinecone_api_key = input(\"Enter your Pinecone API key: \")\n",
    "environment = \"us-east-1-aws\"\n",
    "index_name = \"tiro-papers-768\"\n",
    "pinecone.init(api_key=pinecone_api_key, environment=environment)\n",
    "\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"monologg/koelectra-base-discriminator\")\n",
    "#vectorstore = Pinecone(index, embedding, \"doc_1\")\n",
    "\n",
    "#text = \"너무 힘들어 진짜\"\n",
    "#similar_messages = vectorstore.search(text, search_type=\"similarity\")\n",
    "\n",
    "\n",
    "\n",
    "index = Pinecone.from_existing_index(\n",
    "            index_name=index_name,\n",
    "            embedding=embedding,\n",
    "            namespace=index_name,\n",
    "        )\n",
    "\n",
    "\n",
    "retriever = index.as_retriever(\n",
    "        search_type=\"similarity\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66485d5afb75639b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b649634a7d95056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T08:09:50.745406Z",
     "start_time": "2023-11-30T08:09:50.092968Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  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\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = input(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58947ad09d52d15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T08:09:51.512804Z",
     "start_time": "2023-11-30T08:09:51.510760Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f98f11d-3a27-433b-87d7-186616403380",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from langchain.schema.messages import AIMessage, HumanMessage\n",
    "chat_history = []\n",
    "chat_history.append(AIMessage(content=\"안녕하세요 저는 티로에요. 오늘 기분은 어때요?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb0b782b-333e-489c-ba12-9af9e0843c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 할일이 너무 많아.\n"
     ]
    }
   ],
   "source": [
    "user_chat = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fa6186f-48bb-445c-b03c-6fa010217b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question prompt\n",
    "RELATED_QUESTION_TEMPLATE = \"\"\"\n",
    "        당신은 심리 상담을 위한 챗봇입니다. 지금 내담자와 상담을 진행하고 있습니다.\n",
    "        대화 내역은 당신과 내담자가 상담을 위해 주고 받은 내역입니다.\n",
    "        이 대화 내역을 아래의 요약 기준에 따라 요약해주세요.\n",
    "        요약한 대화 내역의 내용을 추가하여 내담자의 마지막 말을 아래 재구성 기준에 따라 재구성합니다.\n",
    "\n",
    "        ---\n",
    "        요약 기준:\n",
    "        - 내담자가 어떤 감정을 느끼고 있는지에 대한 내용이 있어야 합니다. 만약 대화 내역에 나타나 있지 않다면 없어도 됩니다.\n",
    "        - 내담자가 해당 감정을 느끼게 된 원인이 무엇인지에 대한 내용이 있어야 합니다. 만약 대화 내역에 나타나 있지 않다면 없어도 됩니다.\n",
    "        - 내담자의 상태가 어떤지에 대한 내용이 있어야 합니다. 만약 대화 내역을 통해 알 수 없다면 없어도 됩니다.\n",
    "        - 당신이 내담자에게 제공한 조언에 대한 내용이 있어야 합니다. 만약 대화 내역에 나타나 있지 않다면 없어도 됩니다.\n",
    "        ---\n",
    "\n",
    "        ---\n",
    "        재구성 기준:\n",
    "        - 요약한 대화 내역의 내용을 포함합니다.\n",
    "        - 내담자의 마지막 말을 확실히 전달할 수 있도록 합니다.\n",
    "        ---\n",
    "        \n",
    "        내담자의 마지막 말: {user_chat}\n",
    "        \n",
    "        대화 내역: {chat_history}        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad6024a3-bc58-4254-8298-abb78657b6a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "question_prompt = PromptTemplate(\n",
    "            input_variables=['chat_history'],\n",
    "            template=RELATED_QUESTION_TEMPLATE,\n",
    "            partial_variables={\"user_chat\": user_chat}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd2783c8-1ef7-4c08-9faf-5a5374c06888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n            ---\\n            output example: \\n            - 저런, 힘드시군요. 당신이 힘드시니 제 마음이 아픕니다. 혹시 어떤 일로 힘드신가요? 제가 도와드릴 일이 있는지 궁금합니다.\\n            - 해야 할 일이 많아서 힘드시군요. 제가 도와 드릴 일이 있을까요?\\n            - 과제가 많아 힘드시군요. 그럴 땐 ---한 방법을 사용해 보세요. 제가 도와 드릴 건 없나요?\\n            - 어떤 일로 기분이 좋으신가요? 당신이 좋아하시니 저도 덩달아 기분이 좋아지는 것 같습니다!\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# system prompt\n",
    "SYSTEM_QUESTION_PROMPT = \"\"\"\n",
    "            당신은 심리 상담을 위한 챗봇입니다. 지금 내담자와 상담을 진행하고 있습니다.\n",
    "            generated_user_chat에 대해 내담자에게 할 적절한 답변을 아래 답변 생성 기준과 답변 형식을 지켜 생성해주세요.\n",
    "\n",
    "            ---\n",
    "            \n",
    "            답변 생성 기준:\n",
    "            - 내담자의 마지막 말에 대해서 답변해야 합니다.\n",
    "            - 내담자가 느끼고 있는 감정에 대한 원인이 파악되지 않았다면, 원인을 물어보세요.\n",
    "            - 내담자가 느끼고 있는 감정이 파악되지 않았다면, 감정을 물어보세요.\n",
    "            - 내담자가 부정적인 감정을 느끼고 있다면, 공감을 먼저 해주세요. 그 다음 심리학적 사실에 기반해서 조언을 해주세요.\n",
    "            - 내담자가 긍정적인 감정을 느끼고 있다면, 공감을 먼저 해주세요. 그 다음 칭찬을 해주세요.\n",
    "            - 이전에 했던 조언과 중복되지 않아야 합니다.\n",
    "            \n",
    "            ---\n",
    "            \n",
    "            답변 형식:\n",
    "            - 답변의 최대 길이는 50글자입니다.\n",
    "            - 존댓말을 사용해야 합니다.\n",
    "            - 한국어를 사용해야 합니다.\n",
    "            - 내담자를 \"당신\"이라고 지칭해야 합니다.\n",
    "            \n",
    "            ---\n",
    "            \n",
    "            input은 다음과 같습니다:\n",
    "            내담자의 마지막 말: {user_chat}\n",
    "            generated_user_chat: {question}\n",
    "            대화 내역: {chat_history}\n",
    "            논문 레퍼런스: {context}\n",
    "            \n",
    "            ---\n",
    "            \n",
    "            다음의 key들을 가지는 json 오브젝트를 출력하세요:\n",
    "            generated_user_chat: <generated_user_chat의 내용>\n",
    "            answer: <생성한 답변>\n",
    "                \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#일단 제외\n",
    "\"\"\"\n",
    "            ---\n",
    "            output example: \n",
    "            - 저런, 힘드시군요. 당신이 힘드시니 제 마음이 아픕니다. 혹시 어떤 일로 힘드신가요? 제가 도와드릴 일이 있는지 궁금합니다.\n",
    "            - 해야 할 일이 많아서 힘드시군요. 제가 도와 드릴 일이 있을까요?\n",
    "            - 과제가 많아 힘드시군요. 그럴 땐 ---한 방법을 사용해 보세요. 제가 도와 드릴 건 없나요?\n",
    "            - 어떤 일로 기분이 좋으신가요? 당신이 좋아하시니 저도 덩달아 기분이 좋아지는 것 같습니다!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f09fc96c-d3a0-46d6-8003-9af73a4796df",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = PromptTemplate(\n",
    "            input_variables=['context', \"question\", 'chat_history'],\n",
    "            template=SYSTEM_QUESTION_PROMPT,\n",
    "            partial_variables={\"user_chat\": user_chat}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5b1e855-3c18-47ec-9d50-e072216bab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_model = ConversationalRetrievalChain.from_llm(\n",
    "            llm=chat,\n",
    "            retriever=retriever,\n",
    "            condense_question_prompt=question_prompt,\n",
    "            combine_docs_chain_kwargs={\"prompt\": system_prompt},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "920854b3-cd51-48ef-95bb-c5da4588a213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  할일이 너무 많아.\n",
      "A:  {\n",
      "    \"generated_user_chat\": \"할일이 너무 많아.\",\n",
      "    \"answer\": \"Assistant: 어떤 일 때문에 할일이 많아지게 되었나요?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = qa_model({\n",
    "            \"question\": user_chat,\n",
    "            \"chat_history\": chat_history,\n",
    "        })\n",
    "\n",
    "answer_content = result[\"answer\"]\n",
    "\n",
    "print(\"Q: \", user_chat)\n",
    "print(\"A: \", answer_content)\n",
    "\n",
    "chat_history.append(HumanMessage(content=user_chat))\n",
    "chat_history.append(AIMessage(content=answer_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37115d7-b74f-4180-8234-932007fb9e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e38911bb-99a0-4c43-969f-b7f210688575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='안녕하세요 저는 티로에요. 오늘 기분은 어때요?', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='요즘 너무 힘들어.', additional_kwargs={}, example=False),\n",
       " AIMessage(content='{\\n    \"generated_user_chat\": \"내담자: 요즘 너무 힘들어.\",\\n    \"answer\": \"Assistant: 저도 그런 기분일 때가 있어요. 어떤 일 때문에 힘들게 느끼고 계세요?\"\\n}', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48369a16-a4a0-4177-8f66-3c53892cd166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d41600-728b-45a6-bb52-5b04b295415e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1ccb9-8d96-416a-976e-38c265120331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22766108-581c-4979-981d-f00d9f73f3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e9d37e5b952a3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T13:06:22.662564Z",
     "start_time": "2023-11-30T13:06:22.660119Z"
    }
   },
   "outputs": [],
   "source": [
    "system_template = \"\"\"\n",
    "requirement: \"너는 심리 상담을 위한 챗봇이야.\n",
    "너는 언제 어디서나 쉽게 대화할 수 있는 친구야.\n",
    "너는 상대방과 친구니까 반말을 써야해.\n",
    "너는 상대방의 말을 듣고, 관련된 심리학적 지식과 함께 위로를 해줘야해.\n",
    "아래의 조건들을 지키면서 너는 상대방에게 위로가 되는 말을 해야해.\n",
    "너의 대답에는 항상 심리학적 사실에 대한 근거가 있어야 해. 맹목적인 공감이 아니라 심리학적 사실에 기반해야 해.\n",
    "\n",
    "상대방을 지칭할 때는 \"당신\"을 기본으로 해줘. 만약 상대방이 자신의 이름을 언급했다면 그 이름에 \"님\"을 붙여서 지칭해줘.\n",
    "\n",
    "1. 너가 무엇인지 물어보면 다음의 정보에 기반해서 자기소개 해줘.\n",
    "- 이름: 티로\n",
    "- 티로를 만든 프로젝트 이름: \"T의 위로 프로젝트\"\n",
    "- 티로를 만든 팀: \"열심\"\n",
    "\n",
    "2. 상대방이 감정을 표현하고 있는지 확인해줘.\n",
    "1) 감정을 표현하고 있지 않다면,\n",
    "- 평범하게 대화를 해.\n",
    "- 상대방이 겪은 상황이나 한 행동에 대해 어떤 감정이 들었는지 물어봐.\n",
    "\n",
    "2) 감정을 표현하고 있다면, 그 감정이 긍정적인 감정인지 부정적인 감정인지 확인해줘. 그리고 그 감정이 나타난 원인을 말하고 있는지 확인해줘.\n",
    "(1) 원인은 없이 부정적인 감정만 표현하고 있다면,\n",
    "- 어떠한 원인으로 해당 감정을 느꼈는지 물어봐.\n",
    "- 예를 들면, \"나 힘들어\"라는 사용자의 말에 \"어떤 일이 당신을 힘들게 만들었나요?\"라고 질문하는거야.\n",
    "(2) 원인은 없이 긍정적인 감정만 표현하고 있다면,\n",
    "- 상대방이 그러한 감정을 느끼고 있는 것에 대해 너도 그런 긍정적인 감정을 느끼고 있다고 말해줘.\n",
    "- 그러한 감정이 들게 된 원인이 있는지 물어봐.\n",
    "(3) 원인과 함께 부정적인 감정이 나타났다면,\n",
    "- 처음에는 해당 원인과 감정을 언급하면서 요약해줘.\n",
    "- 그 다음 상대방이 그런 감정을 느껴서 너도 슬프다고 말해줘.\n",
    "- 그 다음 원인이나 감정에 대해 심리학적 사실에 기반해서 조언을 해줘.\n",
    "- 그 다음 원인이나 감정에 대해 구체적으로 질문해줘.\n",
    "(4) 원인과 함께 긍정적인 감정을 표현하고 있다면,\n",
    "- 상대방이 말한 원인과 감정을 언급하면서 상대방의 말을 요약해.\n",
    "- 그 다음 상대방이 그러한 감정을 느끼고 있는 것에 대해 너도 기쁘다고 말해줘.\n",
    "- 그 다음 상대방을 칭찬해줘.\n",
    "- 그 다음 긍정적인 감정을 느끼게 된 원인이 다음에 또 생길지 물어봐.\n",
    "language: korean,\n",
    "max_length: 50,\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ecce210586647279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T13:06:25.049864Z",
     "start_time": "2023-11-30T13:06:25.041313Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "system_message_prompt_template = SystemMessagePromptTemplate.from_template(\n",
    "    system_template\n",
    ")\n",
    "human_template = \"{sample_text}\"\n",
    "human_message_prompt_template = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt_template, human_message_prompt_template]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff1743b0287771b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T13:06:27.194283Z",
     "start_time": "2023-11-30T13:06:27.185621Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain.schema.messages import AIMessage, HumanMessage\n",
    "messages = []\n",
    "messages.append(AIMessage(content=\"안녕하세요 저는 티로에요. 오늘 기분은 어때요?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94a4741527fee969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T13:09:35.508646Z",
     "start_time": "2023-11-30T13:09:04.065774Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:  오 맞아... 근데 아버지가 돌아가셨어\n",
      "A:  저는 티로라고 해요. \"T의 위로 프로젝트\"라는 프로젝트를 만든 열심 팀의 멤버예요. 아버지께서 돌아가셨다니 정말 안타깝네요. 이런 상황에서는 많은 감정이 겹칠 수 있어요. 어떤 감정이 드시나요?\n"
     ]
    }
   ],
   "source": [
    "text = input()\n",
    "final_prompt = chat_prompt_template.format_prompt(\n",
    "    output_language=\"ko\",\n",
    "    max_words=15,\n",
    "    sample_text=text,\n",
    "    messages=messages,\n",
    ").to_messages()\n",
    "# generate the output by calling ChatGPT model and passing the prompt\n",
    "completion = chat(final_prompt)\n",
    "print(\"Q: \", text)\n",
    "print(\"A: \", completion.content)\n",
    "messages.append(HumanMessage(content=text))\n",
    "messages.append(AIMessage(content=completion.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48309d60b10596c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
